### 深度学习基础（李宏毅）

#### 3.1 Local min & saddle point

##### 3.1.1  临界点及其分类

​	$Loss$的微分为0时，梯度下降就不再更新了，训练也会暂停

​	不同于$Local\ min, Saddle\ Point$可以找到让损失更低的路。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251001192324533.png" alt="image-20251001192324533" style="zoom:50%;" />

##### 3.1.2 判断临界值种类的方法

网络本身复杂，所以我们可以给定某一组参数，比如$\theta'$，在$\theta'$附近的Loss函数是有办法写出的：近似为

​						$L(\theta) \approx L(\theta')+(\theta-\theta')^Tg+\frac{1}{2}(\theta-\theta')^TH(\theta-\theta')$

(二阶泰勒）第一项$L(\theta')$表明$L(\theta)和L(\theta')$二者靠得蛮近，第二项$(\theta-\theta')^Tg$中$g$是梯度向量，弥补二者之间的差距。**$g_i = \frac{ \part L(\theta')}{\part\theta_i}$​**

在**$critical \ point$**，$g=0$，因此第二项等于零，故
$$
L(\theta) \approx L(\theta')+\frac{1}{2}(\theta-\theta')^TH(\theta-\theta')
$$
我们可以根据第三项$\frac{1}{2}(\theta-\theta')^TH(\theta-\theta')$来判断在$\theta'$附近的**误差表面($error\ surface$)**

令$\theta-\theta'=v$​， 则

1. 若$\forall v^THv>0$，$\forall L(\theta)>L(\theta')$ ====>**$Local \  min$**
2. 若$\forall v^THv<0$，$\forall L(\theta)<L(\theta')$ ====>**$Local \  max$**
3. 否则                                                ====>$Saddle\ point$

>如果n阶对称矩阵$A$对于$\forall$非零的$n$维向量$x$都有$x^TAx>0$，则称矩阵$A$为正定矩阵
>
>​									      $x^TAx<0$，则称矩阵$A$为负定矩阵

由于$H$通常情况下是对称的，此时我们不需要遍历所有的$v$，而是看**$H$**的特征值                          ==这里有个flag==

$H$的另一个好处是可以在$Saddle\ Point$处指出参数的**更新方向** :  设$\lambda$为$H$的一个特征值，$\mu$是对应的特征向量。对于我们的优化问题，可以令$\mu = \theta-\theta'$，则
$$
\mu^TH\mu=\mu^T(\lambda\mu)=\lambda||\mu||^2
$$
当$\lambda<0$时，有$\lambda||\mu||^2<0$，此时$\frac{1}{2}(\theta-\theta')^TH(\theta-\theta')<0$。此时，$L(\theta)<L(\theta')$ 且 $\theta=\theta'+\mu$， 沿着$\mu$的方向更新，损失就会变小

所以当$g=0$时，我们如果能找到$H$的一个负的特征值，再找到其对应的特征向量，沿着该方向即可更新参数，获得更小的损失



很多时候，**低维度**的$Local\ Min$其实在**高维度**中是$Saddle\ Point$，那么对于多参数的深度学习网络来说，$Local\ Min$的情况是很少的。所以从经验来看，多数时候，我们训练到一个梯度很小的地方，参数不再更新，往往只是遇到了鞍点。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002111811015.png" alt="image-20251002111811015" style="zoom:50%;" />

##### 3.2 批量和动量



  随机梯度下降的梯度上引入了随机噪声，因此在非凸优化问题中，其相比批量梯度下 降更容易逃离局部最小值。

  考虑$GPU$并行运算,发现$BGD$和$SGD$对于**一次**更新和**一个$epoch$**的更新时间与$batch$大小的关系恰好相反

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002112344495.png" alt="image-20251002112344495" style="zoom:40%;" />

如下图我们发现：小的批量大小优化的结果反而是比较好的。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002112605926.png" alt="image-20251002112605926" style="zoom:40%;" />

一种可能的解释是：在不考虑$H$的情况下，使用$mini-batch$计算的$Loss$函数在不同$batch$中表现不同，帮助我们逃离了$Critical\ Point$

同时，一些时候，小批量和大批量的$train\ loss$相同的情况下，在测试集中，大批量表现的比小批量差，出现了过拟合

论文"$On\ Large-Batch\ Training\ for\ Deep\ Learning:\ Generalization\ Gap\ and\ Sharp\ Minima$"中给出的解释，$Train\ Loss$上面会出现多个$Local \ Min$, 它们中有好坏之分：如果局部最小值在一个“峡谷”里面，它是坏的最小值，因为它会使参数在不同数据集中表现的$Loss$差距巨大。而大的批量更有可能落入“尖锐”的最小值中，因为小批量的更新方向比较随机（噪音影响），更有机会跳出去。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002113313767.png" alt="image-20251002113313767" style="zoom:50%;" />

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002114414026.png" alt="image-20251002114414026" style="zoom:50%;" />

##### 3.2.2 动量法

  动量法是另一种对抗$Saddel\ Point\&Local\ Min$的方法

  引入动量后，每次在移动参数的时候，不是只往梯度的反方向来移动参数，而是根据梯度 的反方向加上前一步移动的方向决定移动方向。 

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002114902277.png" alt="image-20251002114902277" style="zoom:33%;" />

#### 3.3 自适应学习率

训练一个网络，训练到后来发现损失不再下降的时候，有时候不是卡 在局部最小值或鞍点，只是单纯的损失无法再下降。

如果在某一个方向上，梯度的值很小，非常平坦，我们会希望学习率调 大一点；如果在某一个方向上非常陡峭，坡度很大，我们会希望学习率可以设得小一点。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002115217098.png" alt="image-20251002115217098" style="zoom:45%;" />

##### 3.3.1 AdaGrad

  梯度更新某个参数$\theta_i$的过程为
$$
\theta^i_t+1\leftarrow\theta^i_t-\eta g_t^i
$$
  $\theta^i_t$在第t个迭代的值减掉在第t个迭代参数$i$算出的梯度
$$
g_t^i = \frac{\part L}{\part \theta^i}\big|_{\theta = \theta_t}
$$
现在要有一个随着参数定制化的学习率，即把原来学习率$\eta$变成$\frac{\eta}{\sigma^i_t}$ 
$$
\theta^i_t+1\leftarrow\theta^i_t-\frac{\eta}{\sigma^i_t} g_t^i
$$
其中
$$
\sigma_t^i = \sqrt{\frac{1}{t+1}\sum_{j=0}^t(g_j^i)^2}
$$
<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002121425413.png" alt="image-20251002121425413" style="zoom:50%;" />                           <img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002121439063.png" alt="image-20251002121439063" style="zoom:50%;" />

##### 3.3.2 RMSProp

  同一个参数需要的学习率，也会随着时间而改变。RMSprop 第一步跟 Adagrad 的方法是相同的，即
$$
\sigma^i_0 = \sqrt{(g^i_0)^2} = |g^i_0|
$$
  第二步更新过程为


$$
\theta^i_2\leftarrow\theta^i_1-\frac{\eta}{\sigma^i_1} g_1^i \ \ \ \ \sigma_1^i = \sqrt{\alpha(\sigma_0^i)^2+(1-\alpha)(g^i_1)^2}
$$
  其中$0<\alpha<1$，之后的过程循环往复
$$
\theta^i_{t+1}\leftarrow\theta^i_t-\frac{\eta}{\sigma^i_t} g_t^i \ \ \ \ \sigma_t^i = \sqrt{\alpha(\sigma_{t-1}^i)^2+(1-\alpha)(g^t_1)^2}
$$
<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002120918329.png" alt="image-20251002120918329" style="zoom:60%;" />



##### 3.3.3 Adam

  $Adam$ 可以看作$ RMSprop$​​ 加上动量，其使用动量作为参数更新方向，并且能够自适应调整学习率。



#### 3.4 学习率调度

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251002135211873.png" alt="image-20251002135211873" style="zoom:50%;" />

  使用自适应学习率后，一开始优化的时候很顺利，但走到红圈后，纵向上的$\sigma$累计减小到了一定程度，学习率突然“爆炸”了。我们可以通过**学习衰减$learning\ rate\ dacay$(学习率退火$annealing$)**实现。随着参数的不断更新，让$\eta$越来越小。

  当然，除了学习率下降以外，还有另外一个经典的学习率调度的方式——预热。预热的方法是让学习率先变大后变小，至于变到多大、变大的速度、变小的速度是超参数。

  $Q$：预热的合理性？

  $A$：我们计算的$\sigma$是一个统计的结果。从$\sigma$可知某一个方向的陡峭程度 ，但我们需要足够的数据支持。所以我们等$\sigma$统计得比较精准以后，再让学习率慢慢爬升。 ==Flag: RAdam==

#### 3.5 优化总结

$$
\theta^i_{t+1}\leftarrow\theta^i_t-\frac{\eta_t}{\sigma^i_t}m^i_t
$$

  $m_t^i$代表过去所有算出梯度的方向做加权的总和。

  注意：虽然$m$和$\sigma$都会使用过去的梯度，但动量$m$是类似梯度的向量和，而$\sigma$是把梯度的平方相加再开根，无方向性。

### 4.分类

#### why not reggresion?

  <img src="F:\pic\m0smPnr.png" alt="m0smPnr" style="zoom:70%;" />

  假设我们的模型是：$y = b+w_1x_1+w_2x_2$，虽然左图看起来有不错的分区，但如果出现了右边这样的离群值，会造成整条回归线受其影响造成分区的失败。

#### Ideal Alternatives 

<img src="F:\pic\E8dWUEY.png" alt="E8dWUEY" style="zoom:57%;" />

尝试这样的处理：

$\bullet$在$function$内再加入一个$function(g)$来转换

​	$\circ$当$g(x)>0$时就当作是类别一，否则为类别二；

$\bullet$此时**损失函数**如果单纯的统计错误次数

​	$\circ$但是这样就无法微分，无法梯度下降

$\bullet$用其他方法？

​	$\circ$ $SVM,\ Perceptron$

#### Probability from Class - Feature

#### <img src="F:\pic\wQuos90.png" alt="wQuos90" style="zoom:66%;" />

  每一个点表示一只宝可梦，现有一个不存在这79只宝可梦的新资料，一个点是海龟的概率？（非0）

  我们可以将这79只宝可梦的资料视为从一个高斯分布里面挑出的。

#### Gaussian Distribution

<img src="F:\pic\mlkKCAA.png" alt="mlkKCAA" style="zoom:50%;" /><img src="F:\pic\In29csy.png" alt="In29csy" style="zoom:50%;" />

  高斯分布，可以视为一个$function(f_{\mu,\Sigma})$，它的输入是一个向量$x$，也就是宝可梦的特征值，输出是$x$从这个分布中被抽取的概率（不全然是），这个分布概率由$\mu(mean)$和$\Sigma(covariance)$

   $\bullet\ \mu:vector\\\bull\ \Sigma:matrix$

  不同的$\mu$相同的$\Sigma$，分布的**最高点**不同； 不同的$\Sigma$相同的$\mu$，**分散程度**不同

 #### Maximum Likelihood

<img src="F:\pic\w7cle4N.png" alt="w7cle4N" style="zoom:67%;" />

#### Maximum Likelihood

<img src="F:\pic\EUETwJx.png" alt="EUETwJx" style="zoom:67%;" />

直接对$L(\mu,\Sigma)$两次偏微分

最后应用最大似然估计，在考虑了宝可梦的7种特征的情况下，这样的分类方法在测试集上的正确率只有54%。

#### **Generative Model整个模型流程**

$1.$预测$x$属于哪一类，若$P(C_1|x)>0.5$则属于第一类，否则属于第二类

$2.$计算$P(C_1|x)$用到贝叶斯公式，对于$Generative\ Model,P(C_1|x)=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$

$3.$理论上任何参数$(\mu,\Sigma)$的高斯分布都可以产生训练数据，所以可以估计$P(C_1|x)\  P(C_2|x)$

$4.$利用**最大似然的方法**，可以求出让似然函数最大的参数$(\mu*,\Sigma*)$，这两个参数分别是训练数据中该类数据的平均值和协方差矩阵。 这样就可以求得$P(C_1|x)$了

#### Modifying Model

  通常来说，不会给每个高斯分布都计算出一套不同的最大似然估计，协方差矩阵是和输入$feature$大小的平方成正比，所以当$feature$很大的时候，协方差矩阵是可以增长很快的。此时考虑到$model$参数过多，容易$Overfitting$，为了有效减少参数，给描述这两个类别的高斯分布相同的协方差矩阵，如下图所示：

<img src="F:\pic\1179840-20190321212225603-818461707.png" alt="1179840-20190321212225603-818461707" style="zoom:67%;" />

  最后的分类结果:右图新的结果，分类的boundary是线性的，所以也将这种分类叫做 linear model。如果考虑所有的属性，发现正确率提高到了73%

<img src="F:\pic\1179840-20190321212353830-1611529413.png" alt="1179840-20190321212353830-1611529413" style="zoom:80%;" />

#### 数学推导

略了。。。

<img src="F:\pic\1179840-20190321215134311-1397506821.png" alt="1179840-20190321215134311-1397506821" style="zoom:80%;" />

最后发现，在生成式模型里面，我们试着找出$\mu,\Sigma,N$就可以得到$w,b$，也就能算出概率

那我们如果直接找$w, b$呢？？



####  Logistic Regression



#### 5 卷积神经网络

  卷积神经网络常用于图像分类。我们将图像描述为一个**三维张量**（长、宽、通道）作为输入。网络的输入往往是向量，因此在将张量输入前，我们会将它拉直。同时注意到图像有大有小，尺寸不一，常见的处理方式是统一尺寸。

   全连接网络：输入的特征向量与每个神经元与之对应的权重向量的数量巨大，导致模型弹性过大，容易过拟合。

  模型的目标是分类，我们将不同的分类结果表示成不同的独热向量，模型的输出通过$Softmax$以后，输出是$\hat{y}$。同时，我们希望$y'$和$\hat{y}$的交叉熵越小越好。

##### 5.1 感受野$receptive\ field$

  对于图象识别模型里的一个神经元，它要做的就是检测图像里面有没有出现一些特别重要的模式$pattern$。所以我们可以一次只看非常小的范围，以让它们检测某些特别关键的模式是否出现。

>  核大小：描述感受野的高和宽

>  步幅$stride$：移动得到新的感受野

> 填充$padding$：填充边界

##### 5.2共享参数$Parameter\ sharing$

  同样的模式可能出现在不同的区域，我可以利用相同的神经元处理不同的感受野，以减少参数。

> 滤波器$(filter)$：参数张量

> 卷积:共享权重时用滤波器扫过一张图像
>
> 卷积核$（convolutional\ layer）$​：感受野加上参数共享

  用到卷积层的网络就叫CNN，卷积神经网络的偏差比较大。 但模型偏差大不一定是坏事，因为当模型偏差大，模型的灵活性较低时，比较不容易过拟合。全连接层可以做各式各样的事情，它可以有各式各样的变化，但它可能没有办法在任何特定 的任务上做好。而卷积层是专门为图像设计的，感受野、参数共享都是为图像设计的。

  如果把CNN用在图像之外的任务，就要仔细想想这些任务有没有图像用的特性。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251004133359348.png" alt="image-20251004133359348" style="zoom:33%;" />

  当一张图像通过一个卷积层里面一堆滤波器的时候，就会产生一个特征映射。假设卷积层里面有 64 个滤波器，产生的特征映射就有 64 组数字。

<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251004133945933.png" alt="image-20251004134018109" style="zoom:45%;" /><img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251004134027194.png" alt="image-20251004134027194" style="zoom:45%;" />

  当训练的层数不断增加,我们发现可以检测的模式就会越大.



##### 5.3 汇聚

  汇聚就是将滤波器产生的一组数字进行**分组**，这里以最大汇聚$max\ pooling$为例：最大汇聚在每一组里面选一个代表， 选的代表就是最大的一个。除了最大汇聚，还有平均汇聚$mean\ pooling$​， 平均汇聚是取每一组的平均值。

  做完卷积以后，往往后面还会搭配汇聚。汇聚就是把图像变小。不过汇聚对于模型的性能可能会带来一点伤害。

  扁平化$(flatten)$：是把图像里面本来排成矩阵样子的东西“拉直”，即把所有的数值“拉直”变成一个向量。<img src="C:\Users\20252\AppData\Roaming\Typora\typora-user-images\image-20251004140430298.png" alt="image-20251004140430298" style="zoom:50%;" />

##### 5.4 应用：下围棋

棋盘上有 19 × 19 个位置

寻找共同点

##### 5.5 Spatial Transformer Layer

  $CNN$并不是完全平移不变性$(transition\ invariant)$当目标小范围移动时，CNN才具有$(transition\ invariant)$，如果目标从左上角移动到了右下角，$CNN$没有平移不变性。同时$CNN$完全不具有$scaling\ invariant$和$rotation\ inviriant$​

   所以我们可以训练一个可以把物体线性变换到模型正常的大小和方向的前置网络$(STN)$:一个可以根据输入图片输出仿射变换参数的网络

<img src="F:\pic\01de0c724c67b3b55b418d18ebc15458.png" alt="01de0c724c67b3b55b418d18ebc15458" style="zoom:53%;" />

  上图是$STN$网络的一个结果示意图，$(a)$ 是输入图片，$(b)$ 是$STN$中的$localisation$网络检测到的物体区域，$(c)$ 是$STN$对检测到的区域进行线性变换后输出，$(d)$ 是有$STN$的分类网络的最终输出。

<img src="F:\pic\e93b9490fb7c3ed91c412d4f640a24db.png" alt="e93b9490fb7c3ed91c412d4f640a24db" style="zoom:67%;" />

  假设在一个全连接层里，n、m代表输出值在输出矩阵的下标，我们通过调整参数，达到平移、放缩的目的
$$
a^l_{nm}=\sum_i\sum_jw_{nm,ij}^la_{ij}^{l-1}
$$

##### $STN$的基本架构

<img src="F:\pic\8874ca88417a30f997cd279a0266ce69.png" alt="8874ca88417a30f997cd279a0266ce69" style="zoom:80%;" />



  主要有三个部分：

​	1、参数预测$Localisation\ net$ 

​	2、坐标映射$Grid\ generator$

​	3、像素的采集：$Sampler$

<img src="F:\pic\e8cb5914035de588df0fd6c86cfde562.png" alt="e8cb5914035de588df0fd6c86cfde562" style="zoom:67%;" />

  									$STL$可以加入$CNN$的任意位置

##### 如何实现参数预测？

  简化一下模型，如果只是旋转、平移、放缩（仿射变换）的话，我们只需要确定6个参数



   <img src="F:\pic\cd952f0d9fe86a9902950a977af52ce0.png" alt="cd952f0d9fe86a9902950a977af52ce0" style="zoom:47%;" />

$[x, y]$对应输出$layer\ L$中的索引, $[x', y']$对应输入$layer\ L-1$的索引

$Layer\ L-1$中$a_{x'y'}^{L-1}$映射到$Layer\ L$中$a^{L}_{xy}$​

核心公式：
$$
\begin{bmatrix}
x
\\y
\end{bmatrix}
=
\begin{bmatrix}
a& b& c
\\d&e&f
\end{bmatrix}
\begin{bmatrix}
x'\\y'\\1
\end{bmatrix}
$$


##### 如何解决小数坐标不可微？- $Sampler$ 插值 $Interpolation$

  计算得到的小数坐标不能通过简单的四舍五入解决，因为四舍五入的做法可能导致梯度不能更新。

<img src="F:\pic\ef8b72f2882cc74c6144b8fd72310079.png" alt="ef8b72f2882cc74c6144b8fd72310079" style="zoom:67%;" />

